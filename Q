口令1：
使用决策树分类法，把文件中的数据进行分类，用python操作，python代码中备注好每步的操作

# 导入所需库
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler

# 第一步：读取数据
df = pd.read_csv('/mnt/data/red wine quality.csv')

# 第二步：特征与标签划分
X = df.drop('quality', axis=1)  # 特征数据
y = df['quality']               # 标签（要预测的质量）

# 第三步：数据标准化（有助于提升模型表现）
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 第四步：划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42
)

# 第五步：创建决策树分类器并训练
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)

# 第六步：在测试集上进行预测
y_pred = clf.predict(X_test)

# 第七步：评估模型性能
print("准确率 (Accuracy):", accuracy_score(y_test, y_pred))
print("\n分类报告 (Classification Report):")
print(classification_report(y_test, y_pred))

==========================================================================================

口令2：
数学上用贝叶斯分类的方法，把文件中数据进行分类，使用python代码编写程序，并备注好每一步的操作

import pandas as pd
import numpy as np
from collections import defaultdict
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# ————————————————
# 1. 读取数据
# ————————————————
df = pd.read_csv('/mnt/data/red wine quality.csv')  # 假设文件路径不变
X = df.drop('quality', axis=1).values  # 特征矩阵，shape = (n_samples, n_features)
y = df['quality'].values               # 标签向量，shape = (n_samples,)

# ——————————————————————————————
# 2. 划分训练集和测试集
# ——————————————————————————————
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# ——————————————————————
# 3. 定义高斯概率密度函数
#   对连续特征，假设每个类别 c、特征 j 满足
#     p(x_j | y=c) = 1/(√(2πσ²)) · exp[−(x_j−μ)²/(2σ²)]
# ——————————————————————
def gaussian_pdf(x, mean, var):
    coeff = 1.0 / np.sqrt(2.0 * np.pi * var)
    exponent = np.exp(- (x - mean) ** 2 / (2 * var))
    return coeff * exponent

# ——————————————————————————————
# 4. 在训练集上计算各类别的先验和各特征的条件统计量
#    先验 P(y = c) = count(c) / N
#    每个类别 c、每个特征 j 需估计 μ_{c,j}, σ²_{c,j}
# ——————————————————————————————
classes = np.unique(y_train)
n_features = X_train.shape[1]

# 存储先验、均值、方差
priors = {}                            # P(y=c)
means = defaultdict(dict)              # means[c][j]
vars_  = defaultdict(dict)             # vars_[c][j]

for c in classes:
    X_c = X_train[y_train == c]
    priors[c] = X_c.shape[0] / X_train.shape[0]
    for j in range(n_features):
        means[c][j] = X_c[:, j].mean()
        vars_[c][j]  = X_c[:, j].var()

# ——————————————————————————————
# 5. 定义预测函数：对每个样本 x，计算后验 P(y=c | x) ∝ P(y=c) ∏_j p(x_j | y=c)
#    取后验最大的类别作为预测
# ——————————————————————————————
def predict(X):
    y_pred = []
    for x in X:
        posteriors = {}
        for c in classes:
            # 先验的对数
            log_posterior = np.log(priors[c])
            # 累积每个特征的对数似然
            for j in range(n_features):
                pdf_val = gaussian_pdf(x[j], means[c][j], vars_[c][j])
                log_posterior += np.log(pdf_val + 1e-9)  
                # +1e-9 防止 pdf_val 为 0 导致 log(0)
            posteriors[c] = log_posterior
        # 选择 log 后验最大的类别
        y_pred.append(max(posteriors, key=posteriors.get))
    return np.array(y_pred)

# ——————————————————————————————
# 6. 在测试集上进行预测并评估
# ——————————————————————————————
y_pred = predict(X_test)

print("准确率 (Accuracy):", accuracy_score(y_test, y_pred))
print("\n分类报告 (Classification Report):")
print(classification_report(y_test, y_pred, zero_division=0))
