#### DCNv2与DCNv1的区别？

- **DCNv1**
  DCNv1 的 Cross 层，权重 W 是一个 d×1 的向量。 它和输入 x 做的是 点积，得到一个 标量。 然后用这个标量和初始输入 x0 做 逐元素相乘，本质就是 对 x0 做全局统一缩放。 整个过程相当于一个 不带激活函数的线性层，特征交互能力很弱，所有特征只能共享同一个缩放系数，无法学习复杂的高阶交叉。

- **DCNv2**
  DCNv2 最核心的改进，就是把 W 从 向量升级成 d×d 的矩阵。 矩阵乘以向量得到的是一个 向量，而不是标量。 再和 x0 逐元素相乘，就相当于 给 x0 的每一个维度都分配独立的缩放系数，实现了真正的 双线性特征交互。 同时 v2 还支持 并行和堆叠两种结构，特征表达能力、模型容量都比 v1 强很多。
- 详细解释：DCNv2 中矩阵乘法输出的向量， 每一位都对应一种聚合后的特征交互模式。 逐元素相乘相当于对不同语义、不同模式做独立缩放， 而不是全局统一缩放， 因此能捕捉更细粒度、更高阶的特征交互。

