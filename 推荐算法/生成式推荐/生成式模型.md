生成式推荐梳理

原文参考：[(11 封私信) 超全&超细的生成式推荐业界落地实践梳理 - 知乎](https://zhuanlan.zhihu.com/p/1989972800342095350)

#### **传统 DLRMs 的核心问题**

1）**稀疏ID Embeddeding问题**：hashID不包含语义，embs占用大量参数
2）**建模范式低效**：采用「Embedding Layer + 序列建模 + 特征交叉」固定范式，存在通信开销大、硬件利用率低的问题，且缺乏可预测的 Scaling Law，无统一的 Token 化处理逻辑。



#### 一. 核心优化方向：

##### 1.1 增强embedding表征：

- MUSE：引入多模态增强embs，并为最终用户兴趣向量 concat一个SimTier输出的兴趣分布统计向量，增强表征emb
- 快手DAS：将离散SID (转为稠密emb) + 协同过滤表征Emb ，通过多损失约束让两个 Embedding 在训练中互相引导、对齐分布，最终收敛为一个融合语义 + 交互的统一表征emb
- 阿里LUM：学习用户行为序列与场景（场景 + 用户行为样本集）的联合关系，以 Condition Token 为 Prompt，聚合用户交互过的 Item Emb 得到用户兴趣向量，再与 Condition Emb 融合增强

##### 1.2 提升行为序列采样效率（Scaling Law）：

- Meta HSTU：传统序列建模是 Q K V 分别通过各自的embedding表映射，HSTU 共享一个线性层 然后 再切分，通过将QKV U(门阀)映射到统一embedding空间，并且对transformer块结构进行精简，实现scaling堆叠提升效果。
- OneTrans：传统DCN+DIN中序列与非序列是分割开的，最后concat学习他们的特征交叉（大多基于共现统计的）。OneTrans提出首先将序列与非序列统一Token化，映射到统一token Space空间中，再进行交叉学习。并且通过金字塔结构，在深层网络中token已经聚合了全文的信息，逐层丢弃掉冗余的不重要的序列token，提升了计算效率与信息利用率，实现scaling堆叠提升效果。



#### 二. Embedding 信息增强

目的：缓解ID Embedding 缺乏语义信息

##### 2.1 MUSE'阿里25（ID Embedding融合多模态Embedding）

- **参考原文**：https://zhuanlan.zhihu.com/p/1981768798810943972

- **传统存在的问题**：候选物品的 ID embedding与用户历史行为的 ID embedding计算相似度（如余弦 / 点积），本质是基于 ID 的语义匹配—— 但这个 embedding 的语义仅来自 ID 的共现关系（如用户点击 A 后点 B，A 和 B 的 ID embedding 相似度高），没有融入物品本身的属性

- **MUSE**：

  ![1770727204871](C:\Users\15301\AppData\Roaming\Typora\typora-user-images\1770727204871.png)

  **1. 多模态预训练（SCL）**：

  - 正样本构造：基于行为日志中「搜索 query 图文 ↔ 购买商品图文」的明确行为链路；
  - 对比学习：采用 MoCo 风格对比学习，得到适配电商任务的多模态 Embedding 表（线上仅查表，参数冻结）；
  - 文本 / 图像特征处理：
    - Query 无图时：使用 BERT-base（扩展电商领域词表：品牌 / 品类 / 属性词，如 “快充头 /anker/PD20W”）融入关键词语义；
    - 商品图文：融合标题 / 副标题 / 属性文本 + 主图 / 详情图首图的特征。

  **2. GSU**：

  - 对用户终身行为序列中每个历史 item，取其多模态向量与目标商品做余弦相似度计算，筛选 Top-K（线上约 50 条）作为 “精研子序列”。

  **3. ESU（SimTier + SA-TA）**：

  **SimTier**：将 Top-K Embedding 分桶，转化为直方图，每个位置映射为 “强相关 / 一般 / 无关”（维度映射：k*emb_dim → len (M)）；

  **SA-TA**:

  - 用目标 ID embedding 和行为 ID embedding 按 DIN/TWIN 方式算出 ID-based 注意力得分；
  - 再把这个得分与多模态相似度 R 做[线性融合](https://zhida.zhihu.com/search?content_id=267416183&content_type=Article&match_order=2&q=%E7%BA%BF%E6%80%A7%E8%9E%8D%E5%90%88&zhida_source=entity)，并加入逐元素乘项，让“ID 权重 × 语义相似度”共同决定最终注意力；
  - Softmax 后对 ID 序列做加权求和，输出 ID 视角的终身兴趣

  ```python
  class IDBasedLifelongInterest(nn.Module):
  """
  融合ID注意力和多模态相似度的终身兴趣计算模块
  核心：DIN/TWIN ID注意力 + 多模态相似度融合 + 加权求和
  """
  def __init__(self, embedding_dim, hidden_dim=128):
          super().__init__()
          self.embedding_dim = embedding_dim
      # DIN/TWIN 风格的注意力计算网络（MLP）
      self.din_attention_net = nn.Sequential(
          nn.Linear(4 * embedding_dim, hidden_dim),  # 4*dim: 交互特征维度（q, k, q-k, q*k）
          nn.ReLU(),
          nn.Linear(hidden_dim, 1)  # 输出单维度注意力得分
      )
      
      # 融合参数：线性融合权重 + 逐元素乘积权重
      self.alpha = nn.Parameter(torch.ones(1))  # ID注意力得分权重
      self.beta = nn.Parameter(torch.ones(1))   # 多模态相似度R权重
      self.gamma = nn.Parameter(torch.ones(1))  # 逐元素乘积项权重
      self.bias = nn.Parameter(torch.zeros(1))  # 融合偏置
  
  def din_attention_score(self, target_emb, behavior_embs):
      """
      按DIN/TWIN方式计算ID-based注意力得分
      :param target_emb: 目标ID embedding, shape [batch_size, embedding_dim]
      :param behavior_embs: 行为ID序列embedding, shape [batch_size, seq_len, embedding_dim]
      :return: id_score: ID注意力得分, shape [batch_size, seq_len, 1]
      """
      # 扩展target维度以匹配行为序列 [batch_size, seq_len, embedding_dim]
      target_expand = target_emb.unsqueeze(1).expand_as(behavior_embs)
      
      # 构造DIN特征：q, k, q-k, q*k（交互特征）
      concat_features = torch.cat([
          target_expand,               # 目标ID embedding
          behavior_embs,               # 行为ID embedding
          target_expand - behavior_embs,  # 差值特征
          target_expand * behavior_embs   # 乘积特征
      ], dim=-1)
      
      # 通过MLP计算基础ID注意力得分
      id_score = self.din_attention_net(concat_features)  # [batch_size, seq_len, 1]
      return id_score
  
  def fuse_score(self, id_score, r):
      """
      线性融合ID注意力得分和多模态相似度R，加入逐元素乘积项
      融合公式：fused = alpha*id_score + beta*r + gamma*(id_score*r) + bias
      :param id_score: ID注意力得分, [batch_size, seq_len, 1]
      :param r: 多模态相似度, [batch_size, seq_len, 1]
      :return: fused_score: 融合后的得分, [batch_size, seq_len, 1]
      """
      # 线性项 + 逐元素乘积项 + 偏置
      fused_score = (
          self.alpha * id_score + 
          self.beta * r + 
          self.gamma * (id_score * r) + 
          self.bias
      )
      return fused_score
  
  def forward(self, target_emb, behavior_embs, r):
      """
      前向传播：计算ID视角的终身兴趣
      :param target_emb: 目标ID embedding, [batch_size, embedding_dim]
      :param behavior_embs: 行为ID序列embedding, [batch_size, seq_len, embedding_dim]
      :param r: 多模态相似度, [batch_size, seq_len, 1]
      :return: lifelong_interest: ID视角终身兴趣, [batch_size, embedding_dim]
      """
      # 1. 计算ID-based注意力得分
      id_score = self.din_attention_score(target_emb, behavior_embs)
      
      # 2. 融合ID得分和多模态相似度R
      fused_score = self.fuse_score(id_score, r)
      
      # 3. Softmax归一化注意力得分（seq_len维度）
      attention_weights = F.softmax(fused_score.squeeze(-1), dim=-1)  # [batch_size, seq_len]
      attention_weights = attention_weights.unsqueeze(-1)  # [batch_size, seq_len, 1]
      
      # 4. 对行为ID序列embedding加权求和
      lifelong_interest = torch.sum(behavior_embs * attention_weights, dim=1)  # [batch_size, embedding_dim]
      
      return lifelong_interest
      
  # -------------------------- 测试示例 --------------------------
  if __name__ == "__main__":
      # 超参数设置
      batch_size = 4
      seq_len = 10
      embedding_dim = 64
      
      # 构造测试数据
      target_emb = torch.randn(batch_size, embedding_dim)  # 目标ID embedding
      behavior_embs = torch.randn(batch_size, seq_len, embedding_dim)  # 行为ID序列
      r = torch.randn(batch_size, seq_len, 1)  # 多模态相似度R（模拟值）
      
      # 初始化模型
      model = IDBasedLifelongInterest(embedding_dim=embedding_dim)
      
      # 前向计算
      lifelong_interest = model(target_emb, behavior_embs, r)
      
      # 输出结果维度验证
      print(f"目标ID embedding维度: {target_emb.shape}")
      print(f"行为ID序列维度: {behavior_embs.shape}")
      print(f"多模态相似度R维度: {r.shape}")
      print(f"ID视角终身兴趣维度: {lifelong_interest.shape}")  # 预期 [4, 64]
  ```




##### 2.2 赋予Sprase Table 语义结构

- 通过设计多组 / 多层 embedding，让不同维度的 embedding 各司其职、协同编码，把单一层 embedding 扛不住的语义信息，拆分 / 叠加到多组 embedding 里共同表达，本质和多层码本的分层编码逻辑一致。

  

##### 2.3 快手广告DAS（语义ID特征增强）

参考原文：[CIKM2025｜快手DAS: 对偶对齐式语义ID推荐系统在快手商业化落地应用 - 知乎](https://zhuanlan.zhihu.com/p/1940818352072265777)

- **核心问题**：

  - SID（语义 ID）：来自多模态内容特征（标题 / 封面 / 视频帧等），编码物品语义；
  - CF（协同过滤）：来自用户行为交互（点击 / 点赞等），反映用户偏好；
  - 传统两阶段方案（先生成 SID 再对齐 CF）易导致信息丢失、对齐不充分，最终限制推荐效果。

- **提出背景**：

  - s解决SID（语义 ID）与 CF（协同过滤）信号语义不对齐问题，同时规避两阶段对齐的信息损失与策略僵化，通过一段式联合训练实现语义与协同信号的互信息最大化。

- **提出方法**：一段式对偶对齐式的语义ID框架

  ![1770728325589](C:\Users\15301\AppData\Roaming\Typora\typora-user-images\1770728325589.png)

  **1）模块初始并行：**

  语义量化分支：S → 量化器（RQ - VAE/RQ - Kmeans）→ 离散 SID（用户 / 物品级）
  CF 去偏分支：用户行为序列（点击 / 曝光）→ 去偏 CF 模块（DSSM/GCN）→ 协同表征 C

  **2）多视角对偶对齐（核心交互）：**	![img](https://wdcdn.qpic.cn/MTY4ODg1ODI2NDgzMzEzMQ_903257_LYhcoRReQ2iWDUX6_1770021181?w=958&h=311&type=image/png)

  **3）联合损失与端到端优化（梯度融合）：**

  **总损失：** L_total = L_quant（量化重建损失）+ λ1×L_align（对齐损失）+ λ2×L_cf（CF 任务损失，如 CTR 预估）		
  **反向传播**：梯度同时更新量化器、CF 模块、对齐模块参数，实现单阶段协同收敛

  **tips**: 离散 SID 通过 lookup 层转为连续向量，与 CF 分支的原生连续 emb C，在同一连续空间中通过损失函数双向对齐、联合更新参数

  **4）联合表征输出（MDAM 融合）：**

  用混合维度注意力模块（MDAM）融合 SID 与 CF 表征，输出联合向量用于下游排序（CTR/ECPM 预估），部署时可缓存量化结果提升推理效率。 

  

##### 2.4 阿里LUM（基于用户行为LLM的特征增强）

- **思路**：使用基于推荐场景数据预训练好的的LLM来处理用户行为序列和Target Item, 提取用户行为序列的User Embed以及Target Item Embed, 用于传统DLRMs精排模型做特征增强。

- **总结**：学习用户行为序列与场景的联合关系，以 Condition Token 为 Prompt，聚合用户交互过的 Item Emb 得到用户兴趣向量，再与 Condition Emb 融合增强，最终从预训练好的商品 Emb 池中匹配出符合场景 + 用户兴趣的推荐结果

- **具体步骤：**

  **1**）**知识构建**：通过增加一个“Condition Token”来引入一些上下文（比如在哪个场景哪个品类下，搜索词是什么），通过Condition Token学习 用户行为 与 某些场景下 的联合概率分布

  - 这里需要人工显式定义 Condition Token 的基础集合，比如：然后再和用户行为序列拼接成训练样本（Condition Token + 行为序列）
    <S> + [Condition Token ID集合] + <SEP> + [用户行为序列ID] + <PAD>...<PAD>
    [0, 2, 101, 3, 10001, 10002, 10003, PAD, PAD, PAD]
  - 通过embs层映射，拼接位置编码 转化为  输入张量（Embedding 向量 + 位置编码向量）
  - 模型通过学习condition与行为序列的样子作为训练集。就像LLM的文本+回答训练一样，作为预训练。然后我们不输入行为序列，此时变成推理，就像LLM根据文本预测回答一样，我们也可以直接通过condition直接预测行为序列。

  **2）知识查询****：推理时通过构造“Condition Token”去查询特定场景（搜索/分类/筛选项）下当前用户可能感兴趣的Item。可类比于LLM里的Prompt约束，让LUM产生受到condition约束的推荐内容

  - 生成多个embs，做平均池化，聚合作为兴趣向量，检索匹配topK
  - 生成一个Item emb，作为兴趣物品，检索匹配topK

  **3）知识利用**：基于前面LUM查询到的结果(包含当前预测的Item的Embedding以及输入用户行为序列后得到多个User Embedding), 用于传统DLRMs精排模型做特征增强。在使用上, 有两种方式,

  - 直接与传统DLRMs的特征做Concat

  - 使用将它们处理成相似度特征去使用, 阿里很多文章都是使用相似度的方式, 比如SimTier/MUSE

    

#### 三、优化模块，深度堆叠

目的：实现Scaling Law

##### 3.0 传统DLRMs弊端（也是限制Scaling Law的瓶颈）：

- PointWise样本格式效率低（信息冗余，不利于scaling Law）：PointWise会存在存储冗余
- 不同长度序列Padding处理（使得scaling的能力被浪费）：序列较短不满足设定长度时，会padding进行补全，拉低模型有效样本密度

##### **3.1 Meta HSTU**

- **解决问题**：

  - 传统推荐（双塔 / 序列模型）：采用「多表解耦」模式，用户、物品各有独立 Embedding 表（甚至无显式行为 Embedding），不同实体的 Embedding 处于割裂空间，靠人工融合（拼接、点乘）或双塔匹配来建立关联，难以学习深层共现关系；
  - HSTU：采用「单表统一」模式，将物品、行为（甚至特殊标识）全部映射为唯一 sid，通过共享 Embedding 表映射到同一向量空间，天然支持模型自主学习实体间的共现、时序、关联关系，无需人工干预，效果更优。通过极致的计算 / 参数开销优化，让模型能高效堆叠更深的层数、支撑更大的参数量，从而完美适配并验证推荐场景的 Scaling Law（缩放定律）

- **HSTU结构：**
  ![1770728563688](C:\Users\15301\AppData\Roaming\Typora\typora-user-images\1770728563688.png)

  - **输入转换**：

    首先将输入的Sid交错离散序列，用 1 个线性层一次性将输入映射为 4 倍隐藏维度的输出，经过激活函数后，再沿隐藏维度切分为 4 个等维度的子表征（Q、K、V、U）
    [batch_size,seq_len] 查表↓
    [batch_size.seq_len,din_model] 线性层映射↓
    [batch_size.seq_len,din_model * 4] 切分↓
    4 *  [batch_size.seq_len,din_model]，分别作为Q K V U

  - **注意力得分计算**
    ![1770693741962](D:\Users\ruijing\AppData\Roaming\Typora\typora-user-images\1770693741962.png)

    rab是一个可学习的偏置项，主要目的是引入了相对位置和相对时间的信息。
    SiLU自带平滑效果，并且保留原始的喜好强度

  - **逐点变换 + 层归一化**
    ![1770693732778](D:\Users\ruijing\AppData\Roaming\Typora\typora-user-images\1770693732778.png)

    带归一化的注意力加权融合 emb，再跟门控做权重输出。

- 训练步骤：

  - 数据构造：HSTU的输出是用户的行为序列，每次交互被拆分为两个Token：Item and Action

  - 数据处理：通过构造的离散序列对模型进行预训练，然后用于两个预测任务：
    - 预测下一个交互的物品 sid（核心任务）：直接预测下一个会交互（感兴趣）的物品sid
    - 预测下一个交互的行为 sid（辅助任务）：辅助模型理解用户对物品的反馈强度，学习行为偏好

##### 3.2 字节OneTrans

![1770728616030](C:\Users\15301\AppData\Roaming\Typora\typora-user-images\1770728616030.png)

- **传统方法**：序列经过DIN进行序列建模 再拼接 非序列特征，Concat后进入MLP进行交叉
  OneTrans：序列特征与非序列特征 统计经过tokenizer映射到同一Token空间下，再进入OneTrans Stack进行交叉

- **提升效果**：把用户序列和用户物品特征在交叉前统一成tokens，映射到一个Token Space中，可以使得特征和序列在单一主干网络中充分交互，实现了提升样本的信息利用效率（从统计共现到语义关联）。

- **技术特点**：

  - **序列与非序列—差异化处理：**
    在OneTrans统一token化了以后，仍然对序列特征和非序列特征进行了差异化处理

    用户 ID / 物品 ID + 其静态特征：采用per-token 独立参数这里的 “独立参数” 不仅是 Embedding 层，还会延伸到特征编码、融合的核心层，确保高异质性特征的处理不被共享参数 “平均化”。

    序列特征（如用户行为序列、物品关联序列）：采用token 参数共享对序列特征做参数共享，既能用共享参数捕捉跨用户 / 跨物品的通用序列规律，又能避免序列 token 的无意义参数量暴涨

  - **金字塔结构——行为序列Tokens 动态地逐层丢弃token**

    首先经过Self-attention、FNN，与Transfomer保持一致。

    然后将输出的token特征经过一个评分器，根据（1）阈值筛选规则 或者 （2）自适应规则 逐步丢弃tokens

    合理性基础：浅层侧重提取 Token 的局部 / 独立特征，深层则会把分散的 Token 信息逐步聚合、融合成全局语义，因此深层的 Token 本身已经承载了更多上下文信息，冗余的 Token 失去了单独计算的价值，这也是逐层丢弃的合理性基础。