#### **RQ-Kmeans？**

它的具体实现是采用了“残差量化”的思想。简单来说，它不是用一层聚类粗暴地映射，而是分多层进行：第一层K-means对原始向量做粗量化，得到一个token和残差；第二层再对这个残差向量做K-means，得到更细粒度的token，如此迭代。这样，最终一个物品就用一串有层次结构的token来表示，量化误差比单层K-means小很多。



#### **RQ-Kmeans具体实现？**

**第一阶段：初始化中心点**

1. 随机选第一个中心点。
2. 计算所有点到已选中心的**最短距离**。
3. 按照“距离越远，概率越大”的规则，选出下一个中心点。
4. 重复，直到选出K个点。

**第二阶段：迭代聚类，形成码本**：

1. **分配**：将所有向量分配给离它**最近**的中心点，形成K个簇。
2. **更新**：对每个簇，**重新计算其所有成员的均值向量**，这个新的均值向量成为该簇的**新中心**。
3. **迭代**：重复“分配”和“更新”两步，直到中心点的位置不再变化（或变化很小）。
4. **得到码本**：最终稳定下来的这K个中心点向量，才是我们需要的**第一层码本**。

用原始向量减去前面所有层的中心向量和，再次作为新的数据，进行Kmeans聚类



#### **RQ-VAE？**

1. 初始化：RQ‑VAE 通过 kmeans++ 初始化每一层的码本中心点
2. 编码器输出连续稠密 embedding 后，每一层都会先经过 MLP 映射到对应量化空间，再通过最近邻距离把 embedding 或残差分配到最相似的码本向量。
3. 更新中心点时不用简单平均，而是用 EMA 指数移动平均，它和普通平均的区别在于：更重视最新样本，历史样本权重指数衰减，让码本更新更平滑、更稳定、不容易坍缩。

通过这样多层残差量化 + MLP + EMA 更新码本，最终把连续 embedding 转化为稳定的多层离散表示。



#### **RQ-VAE与RQ-Kmeans区别？**

RQ‑VAE 和传统 k‑means 最核心的区别

1. 不是直接对原始特征做聚类，而是先通过 MLP 把特征映射到更适合量化的空间，用 MLP 的大容量参数去捕捉复杂分布，比单纯 k‑means 聚类的表达能力强得多；
2. 码本更新不再是离线聚类，而是用 EMA 指数移动平均在线动态更新，更重视最新数据，平滑稳定、适合端到端训练，满足生成模型在线更新的核心需求；