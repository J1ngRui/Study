**1.介绍一下你的天池新闻推荐项目吧？**

我的项目主要有两个模块，分别是召回和排序。
召回阶段使用了物品协同过滤、用户协同过滤和YoutubeDNN的双塔召回的多路召回策略，并引入基于文章内容emb相似度的冷启动召回作为补充。
排序阶段使用了LightGBM分类模型 + LightGBM排序模型+DIN深度兴趣网络，最后用的是等比重的加权融合各路排序的效果。

**2.先介绍一下你的具体的召回思路吧？**

首先是用协同过滤计算需要的相似度，找到有过交互记录的用户，再遍历用户下所有的物品对进行物品相似度的计算；用户协同也类似。再利用faiss数据库基于文章内容的embedding作一个内容相似度计算，我是直接取的内积，为每一个文章都得到topk个内容最相似的文章。得到这些相似度以后，就可以协同召回。(统计用户点击数量，作min-max归一化)
（1）首先是物品协同召回：遍历有过历史交互行为用户，获取用户的历史点击物品序列，对每一个历史物品，我们都会拉取与该物品相似度最高的topK个物品作为候选物品，对历史物品与候选物品求得分：创建时间差 * 历史序列位置 * 内容相似度ij和ji * 相似度。如果不足召回数量，用热门物品补全
（2）然后是用户协同召回：找到所有有过历史交互的用户，根据u2u找到与当前用户相似的topk个用户。用相似物品的历史行为物品作为候选物品，对这些候选物品与推荐用户的历史物品序列累加计算得分，序列位置 * 内容相似度 * 创建时间差 = 得分
接下来就是YoutubeDNN召回

追问：为什么要做余弦相似度归一化？
如果一个物品 j非常热门（即 item_cnt[j]很大），那么即使它和物品 i的共现次数 wij较高，除以较大的 math.sqrt(item_cnt[i] * item_cnt[j])也会使得最终的相似度得分降低。这可以防止热门物品与大多数物品都产生高相似度，从而让推荐结果更多样化，更关注于用户个性化的兴趣，而不是流行趋势。

**3.物品相似度如何计算？或者用户相似度如何计算**

这里计算物品相似度的权重主要是用了点击的先后顺序、点击序列中间隔的长度、点击间隔的时间差、创建时间的权重。因为是累加相似度进行计算，所以也会对物品相似度引入一个热门用户的惩罚，防止贡献度占比过大。
用户协同过滤的话就比较简单，权重就是两个用户活跃度的平均值然后再乘以一个放大系数，这样可以"两个活跃用户的共同行为更有意义"。
最后都引入了一个余弦相似度归一化

**4.能讲一下YoutubeDNN的代码思路吗?**

**（1）建立映射**
从全量点击日志中提取所有出现过user_id和 item_id，将它们统一编码为连续的整数索引，以满足 Embedding 层的输入要求，同时保存原始 ID ↔ 索引 ID的映射关系，以便在召回或推断阶段将模型输出映射回原始 ID

**（2）数据集正负样本构造**
首先通过 train_set.csv 提取的 原始数据集data 进行提取，提取到每一个用户与用户的物品点击序列。
负样本：当前用户未点击过的 有过被交互行为的文章序列
（为什么是有过交互的呢？因为简单可行，并且作为head negetive负样本质量更高）
（为什么不用全量的？ 因为是多路召回，youtubeDNN负责精准推荐优质内容）
正样本：用滑动窗口进行正样本构造，例如[0,1,2,3,4,5,6]，可以构造[0],[0,1],[0,1,2]…[0,1,2,3,4,5]作为正样本，再把最长的序列作为测试样本
在 YouTubeDNN 中，不管是正样本还是负样本，都会经过同一套网络结构（同一套 user 塔 + item 塔），参数完全共享；区别只体现在 loss 上：正样本被拉近 user embedding，负样本被推远。

**（3）feature column**
将训练集样本手动feature_column,规定user_id送入user_dnn,将hist_article_id映射到click_article_id,并指定cilck_article_id送入物料塔
基于group 的分发逻辑
模型构建函数(如 build_youtubednn_model)内部会根据你在Featurecolumn中定义的group名称对特征进行分组。所有group为user_dnn的特征会被拼接起来，送入用户侧的DNN网络;而group为target_item的特征则被送入物品侧的DNN网络。hist_article_id的group是raw_hist_seq，它通常意味着这个序列特征在进入用户塔之前，会先经过一个聚合层(如你指定的combiner='mean’平均池化)
嵌入共享的精妙设计
hist_article_id字段通过 emb_name='click_article_id'指明，它不创建自己的嵌入矩阵，而是与click_artic1e_id共享同一个嵌入矩阵。这样做有两个核心好处:
。参数效率:模型只需学习一套物品的向量表示，大幅减少了参数量，这对于拥有百万级物品的推荐系统至关重要。
。语义空间统一:确保了用户历史行为中的物品和当前要预测的目标物品在同一个向量空间中，从而可以计算它们之间的相关性(例如，通过注意力机制)

**(4)  训练阶段**
采用Sample Softmax Loss,对一个候选集合{样本，负样本集合)求Loss其中正样本作为分子，负样本与正样本uv和共同作为分母，对分式取负号再去反向传播调整模型各参数(MLP以及其他神经网络层
1.用户塔:接收 user_id和经过平均池化聚合后的hist_article_id等信息，通过一个多层DNN(塔式结构，神经元数量逐层减半)，输出一个固定维度的用户向量。
2.物品塔:接收click_article_id，通过一个神经网络(可能结构更简单)，输出一个与用户向量同维度的物品向量。
3.损失计算:模型的目标是最大化正样本(用户点击过的物品)的用户向量和物品向量的内积(相似度)，同时通过负采样技术(对应你的1oss:'sampledsoftmaxloss'来区分负样本，从而学习参数。
线上服务(Serving)阶段
1.物品塔:提前计算好全量物品的向量，并存入向量检索引擎(如FAISS)
2.用户塔:实时根据用户的最新特征(如变化的hist_artic1e_id)生成用户向量。
3.检索:将用户向量送入检索引擎，进行近似最近邻(ANN)搜索，快速找出最相似的Top-K个物品作为召回结果。这种设计完美平衡了推荐的准确性和服务的效率。

**（5）提取模型训练好的embedding**
user_embedding = user_model.predict(user_id)
item_embedding = item_model.predict(item_id)
对提取的embedding作归一化处理，消除量纲的影响,创建原始id与embedding的映射

**（6）创建faiss对象**
用所有物品向量构建索引，然后对每个用户向量进行最近邻搜索，找到内积最大的topk个物品

**5.YoutubeDNN的Loss是什么？**

Sampled Softmax = Softmax 的高效近似
（1）解决全量候选计算不可行的问题保留了正负样本区分的训练效果
（2）大幅提高训练速度，节省内存
（3）可扩展到亿级物品推荐系统

**6.YoutubeDNN里的共享embedding的好处有哪些？**

（1）提高参数效率：模型只需学习一套物品的向量表示，大幅减少了参数量
（2）统一语义空间：确保了用户历史兴趣和候选物品在同一个向量空间中，从而可以计算它们之间的相关性
（3）缓解稀疏性问题

**7.嵌入层是什么？**

你可以把嵌入层理解为一个可学习的查找表(Lookup Table)6。其工作流程非常直观:
1.初始化:嵌入层是一个大小为[词汇表大小，嵌入维度]的矩阵。例如，若有1万个不同的商品，为每个商品学习一个64维的向量，这个矩阵的形状就是[1e00e，64]。初始时，矩阵中的值通常是随机的46。
2.查找:当输入一个商品的ID(比如整数5)时，嵌入层会简单地查找矩阵中第5行的向量，并将其作为输出6。
3.学习:在模型训练过程中，通过反向传播算法，这个嵌入矩阵中的参数会不断被优化。模型的目标是让有共现或相似关系的对象(比如
经常被同一用户点击的两个商品)的嵌入向量在空间中的距离越来越近，从而让向量空间中的几何关系反映出真实的语义关联

**8.介绍一下你的冷启动召回是什么？（规则直接筛选）**

好的，面试官。我这边做的是文章的冷启动。
冷启动的核心问题是新文章没曝光、没用户交互数据，所以没法用常规的协同过滤这类方法。我们当时的思路是，没有交互记录，我们可以选择利用他的静态特征去跟用户的历史行为进行匹配
比如先根据用户历史交互物品序列，基于与文章embedding的相似度召回一部分文章。
然后根据用户没有看过这篇文章、主题要类似、 字数的差值不是很大 、创建时间与用户最后一次点击的时间差啊也不长，进行规则筛选。

追问：优缺点？
它的优点很明显：规则直观，可解释性强，计算开销小，非常适合在召回阶段快速处理大量候选集。但局限性也有不少，比如规则本身比较‘硬’，阈值（像200字、90天）都是人工设定的，可能不够灵活。而且它非常依赖第一步内容召回的质量，如果第一步就偏了，后面过滤得再好也白搭。

**9.多路召回结果如何合并？**

多路召回合并就是将前面所有的召回策略得到的用户文章列表合并起来。
首先每一路召回都是有得分的，他们之间的量纲是不一样的，我们需要给他们统一的进行排序。所以可以先做一个min-max的归一化，把他们都映射到0-1的区间上，然后可以对每一轮召回结果，分配一些不同的权重，来做最终的这个融合。我是直接对所有路都设置了同样的1.0的一个值，这个东西后面也可以再调。
min-max归一化：，压缩至0-1，保持原始分布形状

**10.召回过程中有什么评估指标吗？排序呢？**

**NDCG（Normalized Discounted Cumulative Gain）**
“NDCG 是用来衡量排序效果的指标，它会看每个推荐物品的相关性和它的位置。如果相关的物品排在前面，它会得更高的分数。越往后排的物品，贡献越小。简单来说，NDCG 让你知道，推荐的内容是否对用户来说有意义，且这些内容有没有排在最前面，避免相关的物品被排在最后。”：累计折损增益 / 实际增益
**AUC（Area Under Curve）**
ROC曲线 的横轴是假正率，纵轴是真正率
假正率：所有真实为负被预测为正，FP /（FP+TN）
真正率：召回率 TP/(TP+FN)
“AUC 是一个用来评估分类模型的指标，尤其适合二分类问题。它计算的是模型区分正负样本的能力，值越高，说明模型越擅长分辨哪些是正样本，哪些是负样本。它主要看 ROC 曲线下面积，越大的面积意味着模型表现越好。在推荐系统中，AUC 反映了系统能多好地把相关和不相关的物品分开。”
**MRR：**MRR的全称是平均倒数排名，它是衡量一个排序系统（如搜索引擎、智能问答、推荐列表）将第一个正确答案或相关项目排在靠前位置能力的经典指标。
**召回率（Recall）**：在所有真实为正的样本中，有多少被你成功找出来了，真正率
“召回率就是看推荐系统能找到多少相关的物品，它计算的是系统召回的相关物品占所有相关物品的比例。简单来说，就是系统能不能覆盖到用户真正感兴趣的内容，召回率高说明能找到更多的相关物品，但它也可能带来一些不相关的物品。所以，召回率和精度需要一起看，才能知道系统的真正表现。”
Recall = TP / (TP + FN)  FN：错误预测的负样本 TN：正确预测的负样本
**精度（Precision）**：预测为正的样本中，有多少是预测对的 
“精度是看系统推荐的物品有多少是真的相关，它计算的是推荐的相关物品占所有推荐物品的比例。简单来说，精度越高，说明你推荐的内容越精准，用户看到的相关物品多。如果精度低，就可能推荐了一堆用户不感兴趣的东西，影响体验。它和召回率一样，也需要找到一个平衡。”
Precision = TP / (TP + FP)  TP：正确预测的正样本，FP错误预测的正样本
**F1-score**:“F1-score 是精度和召回率的平均值，它帮助我们综合评估模型的表现。它的优势在于，平衡了精度和召回率之间的关系，尤其在数据不平衡的情况下更有用，比如推荐系统中热门物品占比高，而长尾物品较少。这时，F1-score 能帮助我们同时优化准确性和覆盖度，不会过于偏向其中一个。” 
F1-score = 2 * (Precision * Recall) / (Precision + Recall)

**11.** **介绍一下排序模型吧？**

我的排序模型主要用了LightGBM和DIN网络，最后做了一个简单的加权融合
DIN： [序列建模.md](传统推荐模型\序列建模.md) 
LightGBM： [决策树模型.md](传统推荐模型\决策树模型.md) 

**12.** **你的多排序模型结果是如何聚合的？**

我也是使用了加权融合，每个模型的权重用的是相同的，分数各占1/3。需要额外对LightGBM排序模型做一个min-max归一化，再进行加权。最后进行排序